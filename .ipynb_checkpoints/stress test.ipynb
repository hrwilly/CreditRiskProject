{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7256128",
   "metadata": {},
   "source": [
    "# DURATION-NEUTRAL DTS-TARGET PORTFOLIO OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c45886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036176bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b671e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 72.64101446353888, 2: 278.17262995104056, 3: 1910.5262516642238}\n",
      "     coupon_income  capital_gains  hedge_cost  portfolio_cost  total_return  \\\n",
      "0         1.653149       0.000000    1.981598      100.801612     -0.328449   \n",
      "1         2.320486       0.000000    2.840575       98.425176     -0.520089   \n",
      "2         5.845315       0.000000   11.236825       93.872128     -5.391510   \n",
      "3         1.798250       0.071447   -0.089344      100.950150      1.958994   \n",
      "4         2.202726      -0.217177   -0.132580       98.306263      2.118060   \n",
      "..             ...            ...         ...             ...           ...   \n",
      "388       3.538225      -0.034784    7.288565       96.997763     -3.788799   \n",
      "389       4.124614      -1.811228    3.043216       62.739859     -0.731365   \n",
      "390       5.719701       0.249288    4.858688       96.495854      1.114274   \n",
      "391       3.555080       0.043665   -6.144189       97.443642      9.737910   \n",
      "392       4.125254       1.534066   18.296982       64.512275    -12.622704   \n",
      "\n",
      "     excess_return  portfolio_return       date  bucket  rf_rate  \n",
      "0        -3.251695         -0.003258 2022-05-18       1    0.001  \n",
      "1        -5.441348         -0.005284 2022-05-18       2    0.001  \n",
      "2        -8.489290         -0.057435 2022-05-18       3    0.001  \n",
      "3        -1.271411          0.019406 2022-05-25       1    0.001  \n",
      "4        -1.814191          0.021546 2022-05-25       2    0.001  \n",
      "..             ...               ...        ...     ...      ...  \n",
      "388     -79.447054         -0.039061 2024-11-06       2    0.020  \n",
      "389     -40.884875         -0.011657 2024-11-06       3    0.020  \n",
      "390     -50.993487          0.011547 2024-11-13       1    0.020  \n",
      "391     -70.165876          0.099934 2024-11-13       2    0.020  \n",
      "392     -52.620314         -0.195664 2024-11-13       3    0.020  \n",
      "\n",
      "[393 rows x 10 columns]\n",
      "Total Return: 192.81604616642468\n",
      "Sharpe Ratio: 1.4287905183043192\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pyfolio as pf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load trading data\n",
    "data = pd.read_excel(\"/Users/ottffssdlh/Downloads/TradingData.xlsx\")\n",
    "\n",
    "# Load treasury data\n",
    "Treasuries = pd.read_excel(\"/Users/ottffssdlh/Downloads/TradingTreasuries.xlsx\")\n",
    "\n",
    "# Load risk-free rate (RF) data\n",
    "rf_data = pd.read_csv(\"/Users/ottffssdlh/Downloads/rf_constant.csv\")\n",
    "rf_data.rename(columns={\"Week_Start\": \"Date\"}, inplace=True)\n",
    "\n",
    "# Format datetime columns\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['maturity_date'] = pd.to_datetime(data['maturity_date'], errors='coerce')\n",
    "data['next_call_date'] = pd.to_datetime(data['next_call_date'], errors='coerce')\n",
    "Treasuries['Date'] = pd.to_datetime(Treasuries['Date'])\n",
    "rf_data['Date'] = pd.to_datetime(rf_data['Date'])\n",
    "\n",
    "# Merge risk-free rates\n",
    "data = pd.merge(data, rf_data, on='Date', how='left')\n",
    "data['DTS'] = data['spread'] * data['modified_duration']\n",
    "\n",
    "# Split data into 3 buckets - low, medium, high DTS subportfolios\n",
    "bucket_labels = [1, 2, 3]\n",
    "data['Bucket'] = pd.qcut(data['DTS'], q=len(bucket_labels), labels=bucket_labels, duplicates='drop')\n",
    "\n",
    "# Filter out extreme spread points - keep middle 99.5% of the data\n",
    "lower_quantile = data['DTS'].quantile(0.005)\n",
    "upper_quantile = data['DTS'].quantile(0.995)\n",
    "data = data[(data['DTS'] > lower_quantile) & (data['DTS'] < upper_quantile)]\n",
    "\n",
    "# Filter so spread > 30\n",
    "data = data[data['spread'] > 30]\n",
    "\n",
    "# Define target DTS by bucket (based on given values)\n",
    "low_thresh = np.quantile(data['DTS'], 0.33)\n",
    "mid_thresh = np.quantile(data['DTS'], 0.67)\n",
    "high_thresh = np.quantile(data['DTS'], 1.0)\n",
    "target_dts = {1: low_thresh / 2, 2: (low_thresh + mid_thresh) / 2, 3: (mid_thresh + high_thresh) / 2}\n",
    "print(target_dts)\n",
    "\n",
    "# Group trading data by Date and Bucket\n",
    "trading = data.groupby(['Date', 'Bucket']).apply(lambda x: x).reset_index(drop=True)\n",
    "\n",
    "# Optimizer for Portfolio Weights\n",
    "def portfolio_optimizer(portfolio, target_dts, initial_weights, previous_weights=None):\n",
    "    n = len(portfolio)\n",
    "\n",
    "    def objective(weights):\n",
    "        excess_returns = portfolio['ytm'] - portfolio['RF']\n",
    "        risk_adjusted_return = np.dot(weights, excess_returns)\n",
    "\n",
    "        # Increase penalty for weight concentration\n",
    "        concentration_penalty = 0.05 * np.sum(weights ** 2)\n",
    "\n",
    "        # Increase penalty for high portfolio turnover\n",
    "        if previous_weights is not None and len(previous_weights) == len(weights):\n",
    "            turnover_penalty = 0.05 * np.sum(np.abs(weights - previous_weights))\n",
    "        else:\n",
    "            turnover_penalty = 0\n",
    "\n",
    "        return -risk_adjusted_return + concentration_penalty + turnover_penalty\n",
    "\n",
    "    # Constraints for the optimization problem\n",
    "    constraints = [\n",
    "        {'type': 'eq', 'fun': lambda w: target_dts - np.dot(w, portfolio['DTS'])},\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}  # Weights must sum to 1\n",
    "    ]\n",
    "\n",
    "    # Bounds for weights\n",
    "    bounds = [(0, 1) for _ in range(n)]\n",
    "\n",
    "    # Using previous weights or evenly distributed initial weights\n",
    "    if initial_weights is None or len(initial_weights) != n:\n",
    "        initial_weights = np.ones(n) / n  # Default equal weights if not given or not matching the portfolio size\n",
    "\n",
    "    # Run the optimizer\n",
    "    result = minimize(objective, initial_weights, bounds=bounds, constraints=constraints)\n",
    "    return result.x if result.success else initial_weights  # Return initial_weights if optimization fails\n",
    "\n",
    "\n",
    "def hedge_duration(portfolio_duration, treasury_data, previous_hedge=None):\n",
    "    remaining_duration = portfolio_duration\n",
    "    hedge_results = []\n",
    "    total_hedge_return = 0  # To accumulate the total return from the hedging instruments\n",
    "\n",
    "    # Calculate cost per unit of duration for each treasury\n",
    "    treasury_data['cost_to_duration'] = treasury_data['closing_price'] / treasury_data['modified_duration']\n",
    "    treasury_data = treasury_data.sort_values(by='cost_to_duration')\n",
    "\n",
    "    # Track the used quantities from the previous hedge\n",
    "    if previous_hedge is not None:\n",
    "        previous_hedge_dict = {treasury['treasury_tool']: treasury['used_quantity'] for _, treasury in previous_hedge.iterrows()}\n",
    "    else:\n",
    "        previous_hedge_dict = {}\n",
    "\n",
    "    for _, treasury in treasury_data.iterrows():\n",
    "        if abs(remaining_duration) < 1e-6:\n",
    "            break\n",
    "\n",
    "        tool_duration = treasury['modified_duration']\n",
    "        price = treasury['closing_price']\n",
    "        prev_price = treasury['prev_price']\n",
    "\n",
    "        # Determine the quantity needed for the current duration\n",
    "        used_quantity = remaining_duration / tool_duration\n",
    "\n",
    "        # Adjust the quantity based on the previous day's usage\n",
    "        prev_quantity = previous_hedge_dict.get(treasury['CUSIP'], 0)\n",
    "        quantity_change = used_quantity - prev_quantity\n",
    "\n",
    "        if abs(quantity_change) > 0:\n",
    "            # Calculate return for the treasury bond\n",
    "            treasury_return = (price - prev_price) / prev_price if prev_price else 0\n",
    "\n",
    "            # Calculate the weighted return based on the used quantity change\n",
    "            weighted_return = quantity_change * treasury_return\n",
    "\n",
    "            # Append hedge details to the results\n",
    "            hedge_results.append({\n",
    "                'treasury_tool': treasury['CUSIP'],\n",
    "                'used_quantity': quantity_change,\n",
    "                'cost': quantity_change * price,\n",
    "                'return': weighted_return  # Add return to the results\n",
    "            })\n",
    "\n",
    "        # Update remaining duration to get closer to zero\n",
    "        remaining_duration -= used_quantity * tool_duration\n",
    "\n",
    "    # Add total hedge return to the final results\n",
    "    hedge_results.append({'Total_Hedge_Return': total_hedge_return})\n",
    "\n",
    "    return pd.DataFrame(hedge_results)\n",
    "\n",
    "# Calculate Portfolio Metrics\n",
    "def calculate_portfolio_metrics(sub_data, treasury_hedge):\n",
    "    coupon_income = (sub_data['Weight'] * sub_data['coupon_rate']).sum()\n",
    "    capital_gains = (sub_data['Weight'] * (sub_data['closing_price'] - sub_data['prev_price'])).sum()\n",
    "    hedge_cost = treasury_hedge['cost'].sum() if not treasury_hedge.empty else 0\n",
    "    hedge_returns = treasury_hedge['return'].sum() if not treasury_hedge.empty else 0\n",
    "    portfolio_cost = (sub_data['Weight'] * sub_data['closing_price']).sum()\n",
    "\n",
    "    total_return = coupon_income + capital_gains - hedge_cost + hedge_returns\n",
    "    excess_return = total_return - (sub_data['RF'] * portfolio_cost).sum()\n",
    "    portfolio_return = total_return / portfolio_cost\n",
    "\n",
    "    return {\n",
    "        'coupon_income': coupon_income,\n",
    "        'capital_gains': capital_gains,\n",
    "        'hedge_cost': hedge_cost,\n",
    "        'portfolio_cost': portfolio_cost,\n",
    "        'total_return': total_return,\n",
    "        'excess_return': excess_return,\n",
    "        'portfolio_return': portfolio_return\n",
    "    }\n",
    "\n",
    "def trading_and_hedging(trading_data, treasury_data, target_dts):\n",
    "    results = []\n",
    "\n",
    "    # Sort trading data by Date and CUSIP\n",
    "    trading_data = trading_data.sort_values(by=['CUSIP', 'Date'])\n",
    "    trading_data['prev_price'] = trading_data.groupby('CUSIP')['closing_price'].shift(1)\n",
    "    treasury_data['prev_price'] = treasury_data.groupby('CUSIP')['closing_price'].shift(1)\n",
    "\n",
    "    # Initialize previous weights as None at the beginning\n",
    "    previous_weights = {}\n",
    "    previous_hedges = {}\n",
    "\n",
    "    for date, daily_data in trading_data.groupby('Date'):\n",
    "        daily_treasury_data = treasury_data[treasury_data['Date'] == date]\n",
    "\n",
    "        for bucket in [1, 2, 3]:\n",
    "            sub_data = daily_data[daily_data['Bucket'] == bucket]\n",
    "            target_dts_value = target_dts.get(bucket, None)\n",
    "\n",
    "            if target_dts_value is None or len(sub_data) == 0:\n",
    "                continue\n",
    "\n",
    "            # Get previous weights or assign equal initial weights\n",
    "            initial_weights = previous_weights.get(bucket, None)\n",
    "\n",
    "            # Optimized weights using previous weights as initial guess\n",
    "            optimized_weights = portfolio_optimizer(sub_data[['DTS', 'ytm', 'closing_price', 'RF']], target_dts_value, initial_weights, previous_weights.get(bucket))\n",
    "\n",
    "            # Save the current optimized weights for the next iteration\n",
    "            previous_weights[bucket] = optimized_weights\n",
    "\n",
    "            sub_data = sub_data.copy()\n",
    "            sub_data['Weight'] = optimized_weights\n",
    "            portfolio_duration = (sub_data['Weight'] * sub_data['modified_duration']).sum()\n",
    "\n",
    "            # Adjust the hedge based on previous hedge positions\n",
    "            previous_hedge = previous_hedges.get(bucket, None)\n",
    "            treasury_hedge = hedge_duration(portfolio_duration, daily_treasury_data, previous_hedge)\n",
    "\n",
    "            # Save the current hedge for the next iteration\n",
    "            previous_hedges[bucket] = treasury_hedge\n",
    "\n",
    "            metrics = calculate_portfolio_metrics(sub_data, treasury_hedge)\n",
    "            metrics['date'] = date\n",
    "            metrics['bucket'] = bucket\n",
    "            metrics['rf_rate'] = sub_data['RF'].mean()\n",
    "            results.append(metrics)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Execute Trading and Hedging\n",
    "results = trading_and_hedging(trading, Treasuries, target_dts)\n",
    "print(results)\n",
    "\n",
    "# Calculate Mean Metrics\n",
    "total_return = np.sum(results['total_return'])\n",
    "sharpe_ratio = pf.timeseries.sharpe_ratio(results['total_return'])\n",
    "print(\"Total Return:\", total_return)\n",
    "print(\"Sharpe Ratio:\", sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f64908e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coupon_income</th>\n",
       "      <th>capital_gains</th>\n",
       "      <th>hedge_cost</th>\n",
       "      <th>portfolio_cost</th>\n",
       "      <th>total_return</th>\n",
       "      <th>excess_return</th>\n",
       "      <th>portfolio_return</th>\n",
       "      <th>date</th>\n",
       "      <th>bucket</th>\n",
       "      <th>rf_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.653149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.981598</td>\n",
       "      <td>100.801612</td>\n",
       "      <td>-0.328449</td>\n",
       "      <td>-3.251695</td>\n",
       "      <td>-0.003258</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.320486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.840575</td>\n",
       "      <td>98.425176</td>\n",
       "      <td>-0.520089</td>\n",
       "      <td>-5.441348</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.845315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.236825</td>\n",
       "      <td>93.872128</td>\n",
       "      <td>-5.391510</td>\n",
       "      <td>-8.489290</td>\n",
       "      <td>-0.057435</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.798250</td>\n",
       "      <td>0.071447</td>\n",
       "      <td>-0.089344</td>\n",
       "      <td>100.950150</td>\n",
       "      <td>1.958994</td>\n",
       "      <td>-1.271411</td>\n",
       "      <td>0.019406</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.202726</td>\n",
       "      <td>-0.217177</td>\n",
       "      <td>-0.132580</td>\n",
       "      <td>98.306263</td>\n",
       "      <td>2.118060</td>\n",
       "      <td>-1.814191</td>\n",
       "      <td>0.021546</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>3.538225</td>\n",
       "      <td>-0.034784</td>\n",
       "      <td>7.288565</td>\n",
       "      <td>96.997763</td>\n",
       "      <td>-3.788799</td>\n",
       "      <td>-79.447054</td>\n",
       "      <td>-0.039061</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>4.124614</td>\n",
       "      <td>-1.811228</td>\n",
       "      <td>3.043216</td>\n",
       "      <td>62.739859</td>\n",
       "      <td>-0.731365</td>\n",
       "      <td>-40.884875</td>\n",
       "      <td>-0.011657</td>\n",
       "      <td>2024-11-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>5.719701</td>\n",
       "      <td>0.249288</td>\n",
       "      <td>4.858688</td>\n",
       "      <td>96.495854</td>\n",
       "      <td>1.114274</td>\n",
       "      <td>-50.993487</td>\n",
       "      <td>0.011547</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>3.555080</td>\n",
       "      <td>0.043665</td>\n",
       "      <td>-6.144189</td>\n",
       "      <td>97.443642</td>\n",
       "      <td>9.737910</td>\n",
       "      <td>-70.165876</td>\n",
       "      <td>0.099934</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>2</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>4.125254</td>\n",
       "      <td>1.534066</td>\n",
       "      <td>18.296982</td>\n",
       "      <td>64.512275</td>\n",
       "      <td>-12.622704</td>\n",
       "      <td>-52.620314</td>\n",
       "      <td>-0.195664</td>\n",
       "      <td>2024-11-13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     coupon_income  capital_gains  hedge_cost  portfolio_cost  total_return  \\\n",
       "0         1.653149       0.000000    1.981598      100.801612     -0.328449   \n",
       "1         2.320486       0.000000    2.840575       98.425176     -0.520089   \n",
       "2         5.845315       0.000000   11.236825       93.872128     -5.391510   \n",
       "3         1.798250       0.071447   -0.089344      100.950150      1.958994   \n",
       "4         2.202726      -0.217177   -0.132580       98.306263      2.118060   \n",
       "..             ...            ...         ...             ...           ...   \n",
       "388       3.538225      -0.034784    7.288565       96.997763     -3.788799   \n",
       "389       4.124614      -1.811228    3.043216       62.739859     -0.731365   \n",
       "390       5.719701       0.249288    4.858688       96.495854      1.114274   \n",
       "391       3.555080       0.043665   -6.144189       97.443642      9.737910   \n",
       "392       4.125254       1.534066   18.296982       64.512275    -12.622704   \n",
       "\n",
       "     excess_return  portfolio_return       date  bucket  rf_rate  \n",
       "0        -3.251695         -0.003258 2022-05-18       1    0.001  \n",
       "1        -5.441348         -0.005284 2022-05-18       2    0.001  \n",
       "2        -8.489290         -0.057435 2022-05-18       3    0.001  \n",
       "3        -1.271411          0.019406 2022-05-25       1    0.001  \n",
       "4        -1.814191          0.021546 2022-05-25       2    0.001  \n",
       "..             ...               ...        ...     ...      ...  \n",
       "388     -79.447054         -0.039061 2024-11-06       2    0.020  \n",
       "389     -40.884875         -0.011657 2024-11-06       3    0.020  \n",
       "390     -50.993487          0.011547 2024-11-13       1    0.020  \n",
       "391     -70.165876          0.099934 2024-11-13       2    0.020  \n",
       "392     -52.620314         -0.195664 2024-11-13       3    0.020  \n",
       "\n",
       "[393 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb90726",
   "metadata": {},
   "source": [
    "- calculate mu and sigma using EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "015275fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_1</th>\n",
       "      <th>bucket_2</th>\n",
       "      <th>bucket_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-09-04</th>\n",
       "      <td>0.019233</td>\n",
       "      <td>0.085099</td>\n",
       "      <td>-0.149690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-11</th>\n",
       "      <td>0.025148</td>\n",
       "      <td>-0.044969</td>\n",
       "      <td>0.015357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-18</th>\n",
       "      <td>-0.004449</td>\n",
       "      <td>0.090564</td>\n",
       "      <td>-0.172929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-25</th>\n",
       "      <td>0.058405</td>\n",
       "      <td>-0.060689</td>\n",
       "      <td>-0.005312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-02</th>\n",
       "      <td>-0.022006</td>\n",
       "      <td>0.098431</td>\n",
       "      <td>-0.171227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-09</th>\n",
       "      <td>0.064185</td>\n",
       "      <td>-0.081568</td>\n",
       "      <td>-0.030094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-16</th>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.148111</td>\n",
       "      <td>-0.160638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23</th>\n",
       "      <td>0.070503</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.036136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30</th>\n",
       "      <td>-0.001565</td>\n",
       "      <td>0.098419</td>\n",
       "      <td>-0.196621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-06</th>\n",
       "      <td>0.062733</td>\n",
       "      <td>-0.039061</td>\n",
       "      <td>-0.011657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-13</th>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.099934</td>\n",
       "      <td>-0.195664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bucket_1  bucket_2  bucket_3\n",
       "date                                    \n",
       "2024-09-04  0.019233  0.085099 -0.149690\n",
       "2024-09-11  0.025148 -0.044969  0.015357\n",
       "2024-09-18 -0.004449  0.090564 -0.172929\n",
       "2024-09-25  0.058405 -0.060689 -0.005312\n",
       "2024-10-02 -0.022006  0.098431 -0.171227\n",
       "2024-10-09  0.064185 -0.081568 -0.030094\n",
       "2024-10-16 -0.003794  0.148111 -0.160638\n",
       "2024-10-23  0.070503 -0.041666 -0.036136\n",
       "2024-10-30 -0.001565  0.098419 -0.196621\n",
       "2024-11-06  0.062733 -0.039061 -0.011657\n",
       "2024-11-13  0.011547  0.099934 -0.195664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = results[results[\"date\"] >= \"2024-09-01\"]\n",
    "#result\n",
    "final = result.pivot(index=\"date\", columns=\"bucket\", values=\"portfolio_return\")\n",
    "final.columns = [f\"bucket_{col}\" for col in final.columns]\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42745ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01526617,  0.03368727, -0.09676017]),\n",
       " array([[ 0.00093806, -0.00204475,  0.00228002],\n",
       "        [-0.00204475,  0.00629085, -0.00733096],\n",
       "        [ 0.00228002, -0.00733096,  0.00877039]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_mean = final.iloc[:5][['bucket_1', 'bucket_2', 'bucket_3']].mean().values\n",
    "initial_cov = final.iloc[:5][['bucket_1', 'bucket_2', 'bucket_3']].cov().values\n",
    "initial_mean, initial_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d505ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[ 0.01526617],\n",
       "         [ 0.03368727],\n",
       "         [-0.09676017]]),\n",
       " matrix([[ 0.00093806, -0.00204475,  0.00228002],\n",
       "         [-0.00204475,  0.00629085, -0.00733096],\n",
       "         [ 0.00228002, -0.00733096,  0.00877039]]),\n",
       " matrix([[ 0.06418459, -0.08156826, -0.03009352],\n",
       "         [-0.00379391,  0.14811149, -0.16063778],\n",
       "         [ 0.07050279, -0.04166581, -0.03613557],\n",
       "         [-0.00156493,  0.09841916, -0.19662134],\n",
       "         [ 0.06273263, -0.03906069, -0.0116571 ],\n",
       "         [ 0.01154737,  0.09993377, -0.1956636 ]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vec = np.matrix(initial_mean).T\n",
    "cov_mat = np.matrix(initial_cov)\n",
    "log_ret_mat = np.matrix(final.iloc[5:][['bucket_1', 'bucket_2', 'bucket_3']].values)\n",
    "mean_vec, cov_mat, log_ret_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85662781",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda = 0.97\n",
    "theta = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f96be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ret in log_ret_mat:\n",
    "    ret = ret.T  \n",
    "    cov_mat = theta * cov_mat + (1 - theta) * np.outer(ret - mean_vec, (ret - mean_vec).T)\n",
    "    mean_vec = lamda * mean_vec + (1 - lamda) * ret\n",
    "\n",
    "mean_final = mean_vec.A1\n",
    "cov_final = cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab4d4085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0183272 ,  0.03339146, -0.09838868])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b06587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.00100761, -0.00217215,  0.00230028],\n",
       "        [-0.00217215,  0.00652801, -0.00721661],\n",
       "        [ 0.00230028, -0.00721661,  0.00844626]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be59bf",
   "metadata": {},
   "source": [
    "- Estimate VaRα(Lt+∆) , and using the square root of time rule, estimate VaRα(Lt+K∆) \n",
    "- Use linear loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b9ba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_bucket_1</th>\n",
       "      <th>bucket_bucket_2</th>\n",
       "      <th>bucket_bucket_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-05-18</th>\n",
       "      <td>-0.003258</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.057435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-25</th>\n",
       "      <td>0.019406</td>\n",
       "      <td>0.021546</td>\n",
       "      <td>0.068889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>-0.002694</td>\n",
       "      <td>-0.006057</td>\n",
       "      <td>-0.050918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-08</th>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.025649</td>\n",
       "      <td>0.062463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-15</th>\n",
       "      <td>0.014236</td>\n",
       "      <td>-0.015080</td>\n",
       "      <td>-0.069864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-16</th>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.148111</td>\n",
       "      <td>-0.160638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23</th>\n",
       "      <td>0.070503</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.036136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-30</th>\n",
       "      <td>-0.001565</td>\n",
       "      <td>0.098419</td>\n",
       "      <td>-0.196621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-06</th>\n",
       "      <td>0.062733</td>\n",
       "      <td>-0.039061</td>\n",
       "      <td>-0.011657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-13</th>\n",
       "      <td>0.011547</td>\n",
       "      <td>0.099934</td>\n",
       "      <td>-0.195664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            bucket_bucket_1  bucket_bucket_2  bucket_bucket_3\n",
       "date                                                         \n",
       "2022-05-18        -0.003258        -0.005284        -0.057435\n",
       "2022-05-25         0.019406         0.021546         0.068889\n",
       "2022-06-01        -0.002694        -0.006057        -0.050918\n",
       "2022-06-08         0.020450         0.025649         0.062463\n",
       "2022-06-15         0.014236        -0.015080        -0.069864\n",
       "...                     ...              ...              ...\n",
       "2024-10-16        -0.003794         0.148111        -0.160638\n",
       "2024-10-23         0.070503        -0.041666        -0.036136\n",
       "2024-10-30        -0.001565         0.098419        -0.196621\n",
       "2024-11-06         0.062733        -0.039061        -0.011657\n",
       "2024-11-13         0.011547         0.099934        -0.195664\n",
       "\n",
       "[131 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final2 = results.pivot(index=\"date\", columns=\"bucket\", values=\"portfolio_return\")\n",
    "final2.columns = [f\"bucket_{col}\" for col in final.columns]\n",
    "final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "702d1a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0181629357418736,\n",
       " bucket_bucket_1    2.750063\n",
       " bucket_bucket_2    3.597373\n",
       " bucket_bucket_3   -4.329273\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_portfolio_return = final2.sum().sum()\n",
    "bucket_sums = final2.sum()\n",
    "total_portfolio_return, bucket_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94247f55",
   "metadata": {},
   "source": [
    "- At this time assume we have 1,000,000 dollars to invest and to hedge risks we see three portfolios as a whole to invest\n",
    "- As we can see above, bucket 1 & 2 have positive profit while bucket 3 has a loss. Based on that we assign weight for the whole portfolio: 35% bucket 1; 40% bucket 2; 25% bucket 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e2d2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.95\n",
    "K = 10\n",
    "weight = np.matrix([0.35, 0.4, 0.25]).T\n",
    "cap = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96171ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.matrix(mean_final).T\n",
    "cov = np.matrix(cov_final)\n",
    "VaR_1_day = (- weight.T * mu + np.sqrt(weight.T * cov * weight) * norm.ppf(alpha)) * cap\n",
    "VaR_k_day = VaR_1_day * np.sqrt(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1616f",
   "metadata": {},
   "source": [
    "- keep it as an approximation but may donnot use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f73169b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[16082.24472548]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VaR_1_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7fa21e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[50856.52322075]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VaR_k_day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef47dc9",
   "metadata": {},
   "source": [
    "- Shock the system by assuming a large negative return for bucket 2, the middle one. We want to see the influence to low and high \n",
    "- Assume a −5 sigma shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "476464ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket1_mu = mu[0,0]\n",
    "bucket2_mu = mu[1,0]\n",
    "bucket3_mu = mu[1,0]\n",
    "bucket1_cov = np.sqrt(cov[0,0])\n",
    "bucket2_cov = np.sqrt(cov[1,1])\n",
    "bucket3_cov = np.sqrt(cov[2,2])\n",
    "\n",
    "std_devs = np.sqrt(np.diag(cov))\n",
    "rho = cov / np.outer(std_devs, std_devs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d79e5aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shock_bucket2 = bucket2_mu - 5 * bucket2_cov ** 0.5\n",
    "\n",
    "con_mu_bucket1 = mu[0] + rho[0, 1] * (std_devs[0] / std_devs[1]) * (shock_bucket2 - mu[1])\n",
    "con_var_bucket1 = std_devs[0] ** 2 * (1 - rho[0, 1] ** 2)\n",
    "\n",
    "con_mu_bucket3 = mu[2] + rho[2, 1] * (std_devs[2] / std_devs[1]) * (shock_bucket2 - mu[1])\n",
    "con_var_bucket3 = std_devs[2] ** 2 * (1 - rho[2, 1] ** 2)\n",
    "\n",
    "con_mu_bucket2 = shock_bucket2\n",
    "con_var_bucket2 = std_devs[1] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "982180ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03251437, -0.00924552, -0.05125418])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mu_bucket1 = float(con_mu_bucket1)  \n",
    "shock_bucket2 = float(shock_bucket2)\n",
    "con_mu_bucket3 = float(con_mu_bucket3)\n",
    "mu = np.array(mu).flatten() \n",
    "shock_vector = np.array([con_mu_bucket1, shock_bucket2, con_mu_bucket3])\n",
    "shock_vector = shock_vector.flatten()\n",
    "mu_new = lamda * mu + (1 - lamda) * shock_vector\n",
    "mu_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e5e37eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.00768657, -0.02227025,  0.02452144],\n",
       "        [-0.02227025,  0.06692923, -0.0739892 ],\n",
       "        [ 0.02452144, -0.0739892 ,  0.08224825]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_new = np.zeros_like(cov)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i == j:  \n",
    "            cov_new[i, j] = theta * cov[i, j] + (1 - theta) * (shock_vector[i] - mu[i]) ** 2\n",
    "        else:  \n",
    "            cov_new[i, j] = theta * cov[i, j] + (1 - theta) * (shock_vector[i] - mu[i]) * (shock_vector[j] - mu[j])\n",
    "cov_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bbb6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_k_days(mu, cov, K):\n",
    "    path = []  \n",
    "    sim_mu = np.array(mu).flatten()  \n",
    "    sim_cov = np.array(cov)\n",
    "    for _ in range(K):\n",
    "        x = np.random.multivariate_normal(sim_mu, sim_cov)\n",
    "        path.append(x)\n",
    "        cov_new = np.zeros_like(sim_cov)\n",
    "        for i in range(len(sim_mu)):\n",
    "            for j in range(len(sim_mu)):\n",
    "                if i == j: \n",
    "                    cov_new[i, j] = theta * sim_cov[i, j] + (1 - theta) * (x[i] - sim_mu[i]) ** 2\n",
    "                else: \n",
    "                    cov_new[i, j] = theta * sim_cov[i, j] + (1 - theta) * (x[i] - sim_mu[i]) * (x[j] - sim_mu[j])\n",
    "        sim_mu = lamda * sim_mu + (1 - lamda) * x\n",
    "        sim_cov = cov_new\n",
    "    return np.array(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9029de09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02285439,  0.01412742, -0.08464325],\n",
       "       [ 0.08688695, -0.21378444,  0.15993996],\n",
       "       [ 0.02586382, -0.02553336, -0.01285957],\n",
       "       [ 0.05567459, -0.1245853 ,  0.09623919],\n",
       "       [-0.01112167,  0.12450418, -0.22741004],\n",
       "       [ 0.05586983, -0.09642842,  0.03880403],\n",
       "       [ 0.02540695,  0.04319929, -0.10106412],\n",
       "       [ 0.05447889, -0.05814039, -0.03608341],\n",
       "       [ 0.10381625, -0.15978927,  0.0684715 ],\n",
       "       [-0.03781687,  0.19470424, -0.27413622]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_day_path = simulate_k_days(mu_new, cov_new, K)\n",
    "k_day_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5b6a2f",
   "metadata": {},
   "source": [
    "- simulate over 50,000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e48ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67529d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03251437, -0.00924552, -0.05125418])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55f71ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.00768657, -0.02227025,  0.02452144],\n",
       "        [-0.02227025,  0.06692923, -0.0739892 ],\n",
       "        [ 0.02452144, -0.0739892 ,  0.08224825]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6939f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulations(new_mu, new_cov, N, K):\n",
    "    loss_sim = []  \n",
    "    for _ in range(N): \n",
    "        sim_mu = new_mu.copy()  \n",
    "        sim_cov = new_cov.copy()  \n",
    "        x_add = np.zeros(3)  \n",
    "        for _ in range(K):  \n",
    "            x = np.random.multivariate_normal(sim_mu, sim_cov)\n",
    "            cov_new = np.zeros_like(sim_cov)\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    if i == j: \n",
    "                        cov_new[i, j] = theta * sim_cov[i, j] + (1 - theta) * (x[i] - sim_mu[i]) ** 2\n",
    "                    else:  \n",
    "                        cov_new[i, j] = theta * sim_cov[i, j] + (1 - theta) * (x[i] - sim_mu[i]) * (x[j] - sim_mu[j])\n",
    "            \n",
    "            sim_mu = lamda * sim_mu + (1 - lamda) * x\n",
    "            x_add += x\n",
    "        loss = -np.dot(weight.flatten(), x_add) * cap\n",
    "        loss_sim.append(loss)\n",
    "    return np.array(loss_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cae51ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = simulations(mu_new, cov_new, N, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "059e06ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[89059.58880436]],\n",
       "\n",
       "       [[34792.82643156]],\n",
       "\n",
       "       [[49925.75988566]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[60553.23702877]],\n",
       "\n",
       "       [[72408.49054161]],\n",
       "\n",
       "       [[46073.7507642 ]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56b7f5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51298.95845346303, 92284.26777941933)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave_k_day_loss = np.mean(loss)\n",
    "k_day_var = np.quantile(loss, alpha)\n",
    "ave_k_day_loss, k_day_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c608f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
